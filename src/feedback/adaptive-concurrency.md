# 適應性並行處理

這份心得全部歸功於這部[影片](https://www.youtube.com/watch?v=m64SWl9bfvk)和這篇[部落格文章](https://tech.olx.com/load-shedding-with-nginx-using-adaptive-concurrency-control-part-2-d4e4ddb853be)，因為這份心得將會於 104 TOL 中發表，所以將會以簡報的樣子進行撰寫。

註1：相關 [PPT](https://104cloud-my.sharepoint.com/:p:/g/personal/evan_lu_104_com_tw/ETwKY64XSTtFiNNQLjZHZjkBjgNEEHZRWKO15zkwudYdag?e=nTBfeD) 只能被 104 的員工查看，但本篇以涵蓋全部的內容。

註2：相關[程式碼實作](https://github.com/evan361425/playground-adaptive-concurrency)在 GitHub 上。

## 前言

在今日（2022年），許多人對於適應性並行處理（Adaptive Concurrency）是陌生的，但實際上它自 1988 年便已存在於我們很常使用的協定 [TCP](../essay/web/tcp.md) 當中，他在這之中扮演了什麼角色，又為什麼會重新浮出水面來讓我們重新思考它的價值呢？

在開始前，我想先以銀行作為思考範例，其實這並不是偶然，在後面提到的[利特爾法則](#利特爾法則)中就會讓大家知道為什麼要以銀行作為範例。

### 銀行的並行處理

你現在經營著一家銀行，在實際營業前，我們對於開張後分行的氣氛想像可能如下。

![快樂顧客和快樂行員😄](https://i.imgur.com/prfLso2.jpeg)

而你身為熱情的經營者，會站在顧客和行員中間，幫忙接待套近乎和引導至指定行員，快樂的銀行生活持續不長，事實上在開張後不久你就面臨了這些狀況：

-   冷氣壞掉，原本一個行員十分鐘可以處理一位顧客，因為熱爆所以十五分鐘才能處理一位顧客
-   數抄機壞掉，比冷氣壞掉更糟，現在三十分鐘才能處理一位顧客
-   行員臨時請假，現在銀行完全沒辦法處理顧客的業務了
-   顧客不滿意服務，因為等太久了，顧客把你抓出來臭罵一頓
-   因為某新聞導致業務量大增，顧客數量多到你和行員都沒辦法負荷

![你的銀行正面臨著考驗👻](https://i.imgur.com/l00WB4i.webp)

當這些問題沒有解決，或著連續兩天發生這種狀況，你的銀行就會開始受到顧客的批評，而這種名譽傷害通常需要數倍的時間和金錢來解決。

### 超級保鑣，萊特利米特

為了解決這問題，你請了一位超級保鑣，萊特利米特（Rate Limit），他會透過限制單一顧客的使用總量來減少那些因為特定人士導致的服務品質下降。換句話說，如果有人一天來 30 次，每次都是繁重的業務需要處理 30 分鐘，那你很可能需要限制他來的次數，避免其他顧客因為他而不能使用正常功能。

![超級硬漢 Rate Limit](https://i.imgur.com/9GMCiUV.webp)

但是回想一下我們最一開始的問題，冷氣壞掉、行員請假、業務量合理地大增，這些好像都不是保鑣能夠解決的問題，事實上也沒有任何一家銀行會用這種方式來處理業務等太久的問題。你想像一下，每次進去銀行處理業務就有個保鑣在旁邊計時檢查時間限制，當超過一秒鐘後就把你強制踢出，這種可能讓正常操作的顧客變得惱火的行為，應該是在可預見的未來中不會出現的政策。

聽起來很可笑，但這卻是我們常見於各個網路服務的做法。

## API Management

現在我們把場景回到網路服務中，這裡有個很好的例子，API Management（APIM）。它的定位是承接各個後台服務的中繼站，舉例來說前端使用者在他的電腦按下表格送出時，很可能就會先經過 APIM 再到處理這個表格商務邏輯的服務節點中。這個 APIM 不只是會把流量導到指定的服務中（proxy），他也需要幫我們檢查使用者身份、惡意請求和限制流量。這個角色有沒有聽起來像是在銀行例子中的你，你需要想出個方法來檢查顧客身份、確認是否惡意、確認初步需求後再導流到指定行員。

![APIM 的 Management 代表的意義重大](https://i.imgur.com/Fg5TLbB.png)

接下來我們看看 APIM 即將面臨的一些挑戰。_某個服務的請求突然增加_，導致上游服務和 APIM 本身的負載能力受到挑戰；_請求的總量突然增加_，原因可能不止是外在因素，也有可能是前端的 bug；_上游服務回應速度變慢了_，不管是服務本身的處理速度降低、有程式上的錯或者網路環境等等。

當 _某個服務的請求突然增加_，我們可以透過熔斷機制（或稱限流，Rate Limit）來避免上游和 APIM 本身的服務降載，進而引發全服務的降載。其邏輯大致是當某個服務每分鐘的請求數超過上限，就拒絕接下來五分鐘的所有請求，或者當某個使用者的請求數超過上限，就拒絕接下來時段的所有請求。另外當 _請求的總量突然增加_ 時，我們可以透過自動增長（auto scaling）的機制，增加 APIM 的節點數量，但是當請求增長的速度過快就可能來不及增加節點數，例如[壞掉的服務重啟瞬間](https://tech.olx.com/load-shedding-with-nginx-using-adaptive-concurrency-control-part-1-e59c7da6a6df#5a70)。就算 APIM 有自動增長的機制，但如果上游服務沒有這個機制，對於上游來說突然增加的請求仍然會對服務造成傷害。最後，當 _上游服務降載_ 時，現有的熔斷機制沒辦法快速反應這個服務的健康狀況，此時的熔斷就如同虛設，舉例來說，本來服務每秒可以接受 100 個請求，因此在 APIM 中的設定便限制每秒最多 100 個請求送過去，但是因為服務開始做垃圾回收此時它只能承載 50 個請求，而 APIM 沒辦法感知到這件事並允許超過 50 個請求往上游送，造成服務節點負載過重，直接中斷程序。

APIM 之所以稱為 API Management，就是因為我們期望他能做到**管理 API** 的功能，不僅僅是要做到驗證授權和導流的功能，它也要能避免給予上游服務過多的請求導致其服務崩潰，否則就應該稱其為 Auth Proxy 而非 Management。

### 負載測試

所以問題回到：我要怎麼知道一個服務每秒能承載的量？這個問題聽起來很簡單，其實很複雜。首先我們需要做一個負載測試確認該服務能承擔的負載，但是這個測試需要盡可能的減少和線上環境的差異，例如本地端[常駐程序](https://terms.naer.edu.tw/detail/19337266/?index=1)（daemon）的差異、應用程式的設定差異、網路環境的差異，再來還有測試時是在同一台電腦還是拿多台電腦一起發送多個並行請求嗎？，這些請求的連線需要 [keep alive](../essay/web/tcp.md) 嗎？每個請求的酬載（payload）都要有差異嗎？最後是應用程式本身要測哪些功能？有些功能會需要跑約 10 秒，有些卻是單純的 GET 請求，約在 $30\; ms$ 內回應。

![當並行請求的量上升時，服務的通量在到達高峰後會開始衰退而非維持](https://i.imgur.com/RCHz2Wo.webp)

在測試時也需要注意並行請求數上升時，服務的通量並不會維持在最高水平，而是會開始進入退化期（degradation），這時我們要找的「服務每秒能承載的量」就會是在這個曲線的最高點。所以在測試時不能一昧的增加並行請求的數量然後計算[潛伏](https://terms.naer.edu.tw/detail/19375531/?index=1)（latency），而是要計算通量和並行請求數的平面圖，並同時計算這個服務的容量才能合理得出高請求量時的服務所表現的行為。

??? info "容量和通量是什麼？"

    容量（capacity）和通量（throughput）常常被搞混，但這兩者是完全不同的東西。容量是沒有時間概念的，代表一個服務能承載的總量，通量是有時間概念的，代表一個服務每秒能處理請求的量。
    
    舉例來說，假設一個服務的容量是 $200\; req$，通量是 $100\; req/sec$，當有每秒有 50 個請求被打進這個服務，毫無疑問這服務可以承載這個量，因為根據其通量我們知道它每秒可以處理 100 個請求，所以即使現在每秒有 100 個請求，他也要能處理。問題是當現在每秒有 150 個請求時，這個服務會有什麼樣的行為模式？首先如果一開始的瞬間就有 150 個請求，這個服務都能接受這些請求，因為他的容量是 200，但是因為通量是 100，所以只能消化掉 100 個請求，它肚子裡仍然有 50 個請求未消化，這時來到下一秒（第二秒），因為又有 150 個請求近來，所以肚子裡總計有 200 個請求，這也可以被接受，因為容量是 200。當又來到下一秒（第三秒）時，就會有多出來的 50 個請求被拒絕，因為肚子承載不了 250 個請求。

    這樣容量大有什麼好處？因為請求的數量是不穩的，可能每秒 10 個也可能突然沒秒 150 個，所以高容量代表他能容許這些差異，但是真正處理請求的效率還是要看通量。

### 壅塞控制

所以我們需要一個自動化處理壅塞的控制系統，或者稱壅塞控制（congestion avoidance control）。相關論文始於 1988 年，而最一開始應用的地方是在 TCP 協定中。

![Congestion Avoidance and Control](https://i.imgur.com/Et9MJaQ.webp)

隨著應用後的優勢顯現出來，開始出現一些相關的優化和設計，例如 1995 年的 [Vegas](https://cseweb.ucsd.edu/classes/wi01/cse222/papers/brakmo-vegas-jsac95.pdf)、2002 年的 [AIMD-FC](https://www.researchgate.net/publication/271416487_Additive_increase_multiplicative_decrease-fast_convergence_AIMD-FC)、2004 年的 [BIC](https://ieeexplore.ieee.org/abstract/document/1354672) 等等[各種演算法](https://en.wikipedia.org/wiki/TCP_congestion_control#Algorithms)。如同前言所述，這樣一個算是年代久遠的演算法為什麼又重新浮出水面了呢？就是因為這可以很好的解決我們上面提到 APIM 需要處理的請求管理問題。

??? info "有哪些代理伺服器已經預設支援雍塞控制了呢？"

    並不是每個代理伺服器（proxy）都預設支援，例如 Nginx（community version）、HAProxy 預設都沒有支援，需要額外裝一些外掛，例如 Nginx 需要安裝 lua 的外掛後使用相關的套件，這也是本篇的主要實作。相對而言較新的 [Envoy](https://www.envoyproxy.io/docs/envoy/v1.23.0/configuration/http/http_filters/adaptive_concurrency_filter.html) 和 [Vector](https://vector.dev/docs/about/under-the-hood/networking/arc/)（雖然他不是代理伺服器，但是在資料基礎設施中扮演著類似的角色）都有支援。

最後，出乎意料地，上面提到的很多演算法，竟能透過一個公式簡單歸納起來，那就是 1954 年利特爾提出的利特爾法則。

> ... This relationship is covered very nicely with Little's Law
> [Netflix - concurrency-limit](https://github.com/Netflix/concurrency-limits#background)

## 利特爾法則

![利特爾法則](https://i.imgur.com/2JiSIAh.webp)

利特爾法則（Little's law）於 1954 年利特爾提出。我們回到一開始銀行的例子，如果我現在想要設計銀行的椅子數量或者大廳提供人等待的空間時，就要思考「任一時段中銀行平均而言會有幾個顧客」這個問題，這時就可以使用利特爾透過精妙的推導得出的這個法則。假設銀行每小時平均進來的人數有 30 個人（$30\; p/hr$）而每個人平均處理業務的時間是 6 分鐘（也就是 0.1 個小時，$0.1\; hr$）這樣我們就可以算出平均的顧客人數為 $30\; p/hr \times 0.1\; hr = 3\; p$，三個人。所以我只需要準備三張椅子就可以滿足大部分的情況。

我們再看看一個例子，倉儲中心想要知道 _倉庫要多大來存放這些貨品_，所以他開始計算每天平均送進來的貨品數和每件貨物平均要放多久才會被送出，並得出有每天有 100 件貨品進來且每件貨品要存放三天才會被送出，這時我們就知道這個倉庫要可以放 300 件貨品才夠大。這個計算代表了什麼？即使在計算這個非常抽象的結果「我需要多大的倉庫」時，我僅僅需要兩個參數就可以完成計算，並且不受到貨流程分配、服務分配、服務順序，或任何其他因素影響，厲害吧？

### 網路服務的利特爾法則

我們把例子放回網路服務中，當身為一個 APIM 想要計算這個上游服務現在的通量時，我們就可以開始套用利特爾法則。

**$L$ 代表通量，$\lambda$ 代表請求量，$W$ 代表執行時間**。

沒辦法想像？沒關係，我們來實作。
