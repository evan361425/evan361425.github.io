# 處理競賽情況

如何在高可用性（HA）和高一致性（Consistency）之間做取捨。

## 競賽情況

我們先來看看什麼是競賽情況，再說明解決辦法和其帶來的權衡之計。

假設現在有個應用程式：信箱系統。如果使用者有尚未閱讀的信件時，服務會在應用程式的導航頁面放提示紅點，說明還有幾封信還沒看。我們可以用以下 SQL 搜尋語法達成這件事：

```sql title="取得未讀信件數量"
SELECT COUNT(*)
FROM emails
WHERE recipient_id = 2 AND unread_flag = true
```

隨著應用程式的成長，你發現這樣做會讓 `emails` 這個表格的存取次數變得太多了，於是希望能把未讀信件的數量額外存取在其他表格（去正規化的一種行為）。

每次新增信件之後，應用程式會再送一個資料庫請求，把 `mailboxes` 表格中欄位 `unread` 的數字加一。

```sql title="去正規化以提升效率"
-- INSERT INTO emails ..
-- 新增完之後，再增加未讀信件的數量
UPDATE mailboxes
SET unread = unread + 1
WHERE recipient_id = 2;
```

這時，問題就發生了。

![使用者2明明有新郵件，但是 `unread` 數量沒有正確顯示](https://github.com/Vonng/ddia/raw/master/img/fig7-2.png)

上述例子是因為應用程式一個請求在更新資料，另一個請求卻同時讀取該值，從而觀察到尚未完成的狀態。

> 以這個例子而言，尚未完成的狀態為：`unread` 還沒增加。

這種兩個人同時請求存取（write/read）單一（或多個）物件，我們就稱其為「競賽狀況」。不只是多個物件的存取，我們來看看針對單一物件的存取時造成的競賽狀況：

![同時對單一值加一](https://github.com/Vonng/ddia/raw/master/img/fig7-1.png)

除了加一，可能還有 compare-and-set 這類型的請求。例如，如果該值數量大於五，我就歸零，不然就加一。

> 針對單一值的操作稱作 Single-Object Operations；反之，多個值的操作稱為 Multi-Object Operations。

### 隔離性

要避免上述狀況，就需要讓資料庫擁有隔離性（isolation）。要達成隔離性可以有幾種做法：

-   加一把鎖（lock）。
-   建立快照（snapshot），避免互相影響。
-   建立版本機制（version）。

詳細介紹會在下面講解！

### 容錯性

競賽狀況會形成錯誤的狀態，當發生錯誤時，系統要能有機制處理這些問題，處理錯誤的能力我們稱其為容錯性（Fault tolerance）。

![糗了，新增郵件後卻在更新未讀數量時網路中斷](https://github.com/Vonng/ddia/raw/master/img/fig7-3.png)

以上圖為例，這時，根據應用程式的考量可能有不同作法：

-   全部重來：剛剛新增的郵件讓資料庫自動捨去，讓應用程式重新送一次這一系列的請求。
-   重來錯誤的請求：以本例來說，就是重新加一次未讀數量。
-   給你決定：資料庫告知應用程式發生錯誤，讓應用程式（或使用者）決定該怎麼做。

!!! info "重複做事"

    網路中斷可能發生在任何一段，不管是送過去時，還是回傳回來時。如果是回傳回來，就代表對於資料庫來說，資料已經成功添加進去。只是在通知應用程式他成功時，發生錯誤。這時應用程式如果再重來一次，就會讓資料被重複添加。

    我們可以於請求中添加 ID 來避免這件事發生，不過更細的討論於最後一章「作者期許」中說明。

#### 原子性

上面我們提的其中一種做法：重來錯誤的請求，如果請求的狀態是相依的，重來的機制可能是非常複雜的。例如改了某一值之後，根據結果再改另外一個值。這時讓錯誤的請求重來很可能會形成錯誤的狀態。狀況會因為並行（concurrency）和災難復原（例如我們前面提的 WAL）而變得更為複雜。

通常資料庫的設計者為了避免去重來部分錯誤的請求時所造成的錯誤狀態，會使用原子性（atomic）。這個請求做到一半時，如果發生狀況，就完全捨棄之前做的所有事。

> 我們可以透過把執行的結果存在 `/temp` 的位置下，當請求完成時，再把 `/temp` 下的資料整合進資料庫中。
> 如果過程中有錯，則完全清除 `/temp` 下的資料，而不會把資料庫弄髒。

#### 盡責性

不是每個資料庫都會做重來的機制，有些資料庫為了滿足[高可用性（High Availability）](introduction.md#貫穿本書的目的)等目的，會盡可能做自己能做的事（best effort）。

例如清楚告知應用程式發生了什麼事，例如上個例子中，第二個動作（增加郵件未讀數量）若沒完成，則通知應用程式其未完成，但是第一個動作已經準確完成了。這時應用程式就要自己再重加一次未讀數量，或者在設計應用程式時應考量這個問題而減少這類的去正規化。

### 交易機制

我們來把上面的特性整合起來。如果資料庫在處理請求的時候可以滿足上述特性時，我們稱這一類請求為交易（transaction）。

根據上述特性被滿足的等級（例如完全隔離，同一個值同一時間只能被一個請求讀取或寫入），我們會稱該資料庫可以滿足特定等級的資料一致性（consistence）。

![交易機制的價值](images/transaction-representation.png)

> 有些人可能會把隔離性和原子性當成一件事，但是實際代表的意義是不同的。
> 隔離性：避免其他請求（甚至線程）看到部分的結果，以上述郵件為例就是未讀郵件數量還沒增加就可以讀取未讀郵件。
> 原子性：為了達成容錯而把所有處理包裝成單一事件的設計理念（philosophy），其中並沒有並行（concurrency）的概念。
> 原子性是從 atomic 翻譯而來，在此也許用 abortability 更為恰當。

!!! warning "名詞意義"

    實際上，各個名詞的意義在溝通過程中，都已被泛化。在本文章中針對名個詞做的解釋並不適用所有的產品文件、部落客文章、書本。

    你必須通過前後文對照來找出其代表的意義，不必執著於哪個用法才是最為精準的。

### 應用

不是每個應用程式都需要使用交易機制，雖然他能提升容錯性並達成資料的一致性，卻會降低效能和可用性。除此之外，我們也可以透過交易以外的方式來達成一定等級的資料一致性。

1975 年，IBM 的 System R（[第一個 SQL 資料庫](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.84.348&rep=rep1&type=pdf)）首開先河的使用交易的機制。這之後，許多的關連式資料庫（SQL DB）都一定程度上的支援相似的理念。

但是到了 2010 年左右，[NoSQL](data-model.md) 的理念開始崛起。他們提倡的不只是[不同的資料架構](data-model.md#文件式模型)，也放棄使用多值（multi-object）的交易（單一值的交易很輕易就能達成，然而多值的交易卻需要付出龐大的代價），也由此，達成高擴增性、高可用性和高效能的資料庫。

!!! info "ORM 對交易的看法"

    Object-relational mapping（ORM）的框架在處理交易時，並沒有預設 retry 錯誤的交易。

    儘管交易的價值就在於透過原子性當交易失敗時，你可以放心地重跑一次交易。然而，事實上並不是所有場景的都適合重做交易：

    - 資料庫在回應給應用程式時發生網路錯誤，造成實際資料庫已經跑完，而應用程式以為沒跑完。這時就要有應用程式層級的去重複（de-duplication）邏輯
    - 當資料庫因為大量請求而導致忙不過來並回應錯誤，重做一次只會讓狀況更糟糕
    - 當你的程式碼有錯或者請求寫入的值不符合綱目等等，重做一次並不會讓他執行成功

## 一致性等級

一致性等級從低到高，其犧牲的是效能、可用性、擴增性。

![要求越強的一致性，會帶來一些犧牲](images/consistency-sacrefice.png)

這裡解釋的方式是使用較為生活化、範例性的說明，若需要暸解精準的定義，可以查看論文[1][2][3]。

> 最終一致性（eventual consistence）代表在確定但不可預期的未來（不管是人為介入還是網路中斷的復原）裡，資料會被達成一致。
> 這是最弱的一致性，在考慮資料的一致性時，通常都預設資料庫有這一類型的保證。

### 使用提交後的資料

所謂的「使用」有兩種：讀取和寫入。以上述郵件為例，就是一種「讀未完成的資料」（dirty read），而下述例子代表「覆寫未完成的資料」（dirty write）：

![因為可以覆蓋掉別人還沒寫完的資料，很可能會造成破碎的狀態](https://github.com/Vonng/ddia/raw/master/img/fig7-5.png)

因為 _Alice_ 和 _Bob_ 的資料彼此被覆寫了，所以導致最終的狀態破碎化：購買者是 _Bob_，發票上的收件者卻是 _Alice_。

我們稱這種狀況代表資料庫並沒有「使用提交後的資料」（read committed）。要達成這等級的一致性解決辦法通常就是加鎖，幾乎每個資料庫都有實作本等級。

!!! tip "資料遺失並不代表複寫未完成的資料"

    如果 _Alice_ 和 _Bob_ 先後完成請求，並且彼此被覆寫僅有一方被覆寫，這時並不違反_使用提交後的資料_。這只是代表資料遺失了，我們會在下面提到資料遺失的解決辦法。

#### 覆寫未完成的資料

當寫入多筆資料時，鎖住寫過的物件。 以上述為例，當 _Alice_ 尚未完成交易（un-commit）前，`listings id=1234` 的物件會被鎖住，即使 _Bob_ 想修改，也需要等 _Alice_ 完成交易。

#### 讀未完成的資料

若其他請求正在寫入資料時，我們避免其他請求並行讀取時，會大量降低效能（OLTP 的特性是大量讀取少量異動）。所以通常在實作鎖的時候，僅會避免同時寫入。

但是這樣就沒辦法達成我們要求的一致性等級：只讀完成的資料（no dirty read）。我們可以讓正在寫入的資料放在記憶體中，這時其他請求在讀取時，就是讀磁碟裡的資料，這樣就可以避免其他請求讀取到還未完成的資料。當正在寫入的資料完成時，再把做好的資料放回磁碟中。

> 已知的資料庫中，僅有 Microsoft SQL Server 當設定 [`read_committed_snapshot=off`](https://docs.microsoft.com/zh-tw/dotnet/framework/data/adonet/sql/snapshot-isolation-in-sql-server#understanding-snapshot-isolation-and-row-versioning) 時會讓鎖住的物件無法被讀取。

### 快照隔離

_使用提交後的資料_，好像已經很符合我們前面對於交易所說的意義：可以無負擔的捨棄（abortable/atomic）、交易間不會互相影響。前面提到的例子，也都可以順利解決，使用者不會再看到有未讀郵件，卻沒有增加未讀郵件的數量（不讀未完成的資料）。然而：

![使用者僅讀交易完成後的資料，卻仍可能讀到交易的不一致性](https://github.com/Vonng/ddia/raw/master/img/fig7-6.png)

有個請求同時讀取到交易開始前和結束後的狀態，這時就會顯示出狀態的不一致性。聽起來好像還好，我再重新整理就可以把狀態恢復原狀，但是你還需要考慮以下狀況：

> 前面的圖提到的 read skew 就代表這個讀取動作因為任何原因（網路排隊、運行暫停等等）被延遲了，導致其讀取的資料是傾斜的（狀態不一致的）。

-   資料庫的備份。當資料庫在針對線上資料庫做備份時，他仍然後遇到上述的問題。如果備份的資料是狀態不一致的，當未來需要用備份資料做復原時，就會造成這種短暫不一致性的資料變成永久性的
-   分析性的搜尋。若你需要做分析全部使用者的狀態時，很可能會得到這種破碎或不合乎邏輯的結果。

我們稱這種狀況沒辦法達成「快照隔離」一致性。要達成這個等級的一致性，通常會使用**多版本並行控制**（multi-version concurrency control，MVCC），這也是很多資料庫會達成的等級。

!!! warning "專有名詞"

    有些資料庫會稱快照隔離為**可重複讀取**（repeatable read）或**序列化**（serializable），這是因為當初以 System R 為基礎建立的 SQL 協定就是使用可重複讀取這個名詞，資料庫為了宣稱其滿足 SQL 協定，就會把這個名詞寫進他們的文件中。

    雖然有論文[4][5]給予這一類的一致性一個定義，但是大部分資料庫在宣稱其擁有可重複讀取的一致性時並未滿足這個定義。更糟的是 IBM DB2 甚至把**序列化**當成**快照隔離**

    - 使用快照隔離的[資料庫](https://dbdb.io/browse?isolation-levels=snapshot-isolation&q=)
    - 使用重複讀取的[資料庫](https://dbdb.io/browse?isolation-levels=repeatable-read&q=)

#### 多版本並行控制

簡單來說，多版本並行控制就是替資料庫的狀態建立多個版本，每個交易只能操作其當下擁有的版本號，這個版本好我們稱其為交易編號（transaction ID，`txid`）。

> 前面我們提到的*使用提交後的資料*就是讓資料庫擁有兩個版本，一個是交易正在修改時的狀態（un-committed）版本，一個是交易完成（committed）後的版本。
> 所有僅作讀取的交易只會使用到交易完成後的版本，而執行寫入的交易就會自己擁有正在修改時的版本（通常存放於記憶體）。

![你只能讀取同一個版本下的資料庫](https://github.com/Vonng/ddia/raw/master/img/fig7-7.png)

當交易在做讀取時，會根據一個一直增加的計數器給予其交易編號（以上圖為例就是 `txid=12`）。這時，資料庫會列出目前有哪些正在執行的交易，待會本交易在操作時，所有正在執行的交易都會被拒絕使用。同時，只能讀取時，小於其擁有的交易編號的資料（以上圖為例就是 `txid=13` 不能被讀取）。

其核心概念就是：所有的讀取都不會影響所有的寫入，反之亦然。

> 賦值的計數器當大於一固定數時是會歸零重算的。

#### 索引

前面我們有提過[資料庫的索引是如何運作的](db-index.md)，但是如果*多版本並行控制*需要被考慮進去時，就需要一些額外的功去調整機制。

一個作法是讓索引指向所有版本的資料（不管是頁導向中指向特定頁或者日誌結構的散列對照表的地址），但是根據不同實作方式可能會有很大的效能差異。

-   PostgreSQL 會盡量讓所有版本的資料都放進同一個頁
-   CouchDB、Datomic、LMDB 當交易需要更新資料時，讓他直接重新建立新的樹狀結構，完成後直接取代舊的樹狀結構。這樣其他讀取的交易就不會受到影響。但是他會需要背景執行垃圾回收和壓縮的工作

> CouchDB、Datomic、LMDB 雖然也是使用 B-Tree 做儲存，但是機制卻是 append-only/copy-on-write。當更新資料時，不去更動舊的頁，而是直接新增一個頁並讓它取代舊頁的位置。

### 寫入傾斜

上面提到的競賽狀況都是不同交易嘗試使用相同的物件，但是競賽狀況也是會發生在當不同交易同時寫入不同物件的時候。

我們先假設一個狀況，醫院在晚上值班的時候必須要至少擁有一個住院醫師，但是一般情況會讓兩個住院醫師值班（也就是允許讓其中一個醫生休假）。若他們同時在排班系統中，申請休假，狀況就發生了。

![透過資料庫的值來判定邏輯運作時，就可能造成過時的判斷](https://github.com/Vonng/ddia/raw/master/img/fig7-8.png)

這時，用前面的解法並沒有辦法達成資料一致性，因為他們更新（或注入）的目標是不同的。

!!! example "更多範例"

    這就是我們常見的，訂票系統被超訂了。另外一個範例也包括預約系統：

    ```sql title="若有空位，則可預約"
    BEGIN TRANSACTION;

    -- 檢查所有現存的與 12:00~13:00 重疊的預約
    SELECT COUNT(*) FROM bookings
    WHERE room_id = 123 AND
    end_time > '2015-01-01 12:00' AND start_time < '2015-01-01 13:00';

    -- 如果之前的查詢顯示沒有重疊的預約（COUNT(*) == 0）
    INSERT INTO bookings(room_id, start_time, end_time, user_id)
    VALUES (123, '2015-01-01 12:00', '2015-01-01 13:00', 666);

    COMMIT;
    ```

    這例子不像醫生的例子，因為醫生例子是會讀取**存在**的值再根據該值做判斷；反過來說，預約系統是根據**不存在**的值做判斷。

    這種不存在的值而造成的寫入傾斜，我們稱其為假體判定（phantom）。

#### 限制狀態

其中一個簡單的解法：constraint

例如使用者帳戶必須 unique。

#### 限制讀取

你也可以根據商務邏輯，讓程式設計師要求某行在這次交易中是被鎖住不同讀取的。

在前面的「更多範例」中的假體判定就無法透過限制讀取來避免寫入傾斜，因為她並不是依靠任一物件作判定，而是根據整體的資料做判定。這時除了鎖住整個表格（table），你也可以透過物化衝突（materializing conflicts）來物化一些資料以達成部份的鎖定。

已前面的預約系統為例，你可以額外建立一個表格，並在其中放入每十五分鐘的時間區間，所以該表會有 `2000-01-01 00:00:00`、`2000-01-01 00:15:00` 等等的值。當你在做會議室有無預約時，可以鎖定該預約時段的值，避免被讀取，這時就可以達到鎖定部分值的效果，也就是讓假體變成實體。

然而這個方法卻會讓你的應用程式變得很髒（在應用程式的程式碼中寫入資料庫的並行控制邏輯），這個做法根據實作場景很可能變得很困難。所以這應該是作為最後手段，比起這方法，你更應該考慮使用[序列化](#序列化)。

1. HA v.s. Consistency，在兩端中選擇不同等級。展示不同等級的一致性並放入線性中（透過例子，但是都有明確定義於論文中）
    - Eventually Consistency <--> Serializable isolation
    - No dirty read
    - No dirty write, enough to call "transaction" QQ
    - No read skew -> snapshot
    - No write skew(phantoms) -> serializability
2. Serializability
    - Actual Serial execution -> don't scale well
    - Two-phase locking(2PL) -> don't perform well
    - Serializable snapshot(SSI, MVCC) 透過快照，找到哪個寫入要退回
3. Lost updates
4. Warnings
    - Testing!
    - ACID is missing points!

為了決定應用程式可以達成的一致性等級，我們就需要了解不同等級的狀況和解決辦法。

雖然這裡提的競賽狀況不管是單或多台資料庫，都會發生，但是處理分散式的競賽狀況會在之後（容錯的分散式服務）才講。

我們必須盡可能思考所有能發生的狀況，並做好充分的測試來滿足這些狀況。

> 即使資料庫宣稱他能達成某些效果，大部分情況你仍需要在使用前做好測試，因為你的情況很可能不是資料庫設計者在開發時考慮的狀況。

!!! quote "我們該怎麼考慮交易機制"

    使用交易機制來保持資料的一致性會帶來效能的影響。與其考慮效能而拒絕使用，不如在設計應用程式時避免「過度」使用交易機制。

    這時，對應用程式設計者來說，就能大量降低時常要考慮競賽狀況所消耗的工時和錯誤。

    —— Spanner：Google 的全球分散式資料庫（2012）

[1]: https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-95-51.pdf
[2]: http://pmg.csail.mit.edu/papers/adya-phd.pdf
[3]: http://arxiv.org/pdf/1302.0309.pdf
[4]: http://pmg.csail.mit.edu/papers/adya-phd.pdf
[5]: http://arxiv.org/pdf/1302.0309.pdf
